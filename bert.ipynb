{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of bert with bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F60EGiUlPiMp"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSy0Vf5H_CEy"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import time\n",
        "import torch\n",
        "from torchtext.legacy import data \n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "## import data from drive\n",
        "## this should be changed depending the address for you\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import os\n",
        "# os.chdir('/content/drive/MyDrive/LTP - myside/')\n",
        "os.chdir('/content/drive/MyDrive/LCT/Language Technology Project/LTP Project') \n",
        "\n",
        "## using cuda if available\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "def read_pickle_file(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        x = pickle.load(f)\n",
        "\n",
        "    return x\n",
        "X_train = read_pickle_file(\"./data/X_train.pickle\")\n",
        "X_test = read_pickle_file(\"./data/X_test.pickle\")\n",
        "y_train = read_pickle_file(\"./data/y_train.pickle\")\n",
        "y_test = read_pickle_file(\"./data/y_test.pickle\")\n",
        "\n",
        "\n",
        "#Reproducing same results\n",
        "SEED = 2019\n",
        "\n",
        "#Torch\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "d = {'text':X_train,'label':y_train}\n",
        "train_df = pd.DataFrame(d)\n",
        "train_df = train_df.sample(frac = 1, random_state=SEED)\n",
        "print(train_df)\n",
        "train_df.to_csv(r'train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQZIhi1HgQHZ"
      },
      "source": [
        "print(type(X_train[0]))\n",
        "print(type(y_train[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6cAort6dgik"
      },
      "source": [
        "with open('train.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    row_count = sum(1 for row in reader)\n",
        "    print(row_count)\n",
        "\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_eval = []\n",
        "y_eval = []\n",
        "\n",
        "with open('train.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    row_num = 0\n",
        "    for row in reader:\n",
        "      # print(row_num)\n",
        "      if row_num == 0:\n",
        "        print(f'Column names are {\", \".join(row)}')\n",
        "      elif row_num < 0.8*row_count:\n",
        "        X_train.append(row[1])\n",
        "        y_train.append(int(row[2]))\n",
        "      else:\n",
        "        X_eval.append(row[1])\n",
        "        y_eval.append(int(row[2]))\n",
        "      row_num += 1\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYjnHS3oht0R"
      },
      "source": [
        "print(type(X_train[0]))\n",
        "print(type(y_train[0]))\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "\n",
        "print(X_train[0])\n",
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBJ7jApBcqLK"
      },
      "source": [
        "print(type(X_eval[0]))\n",
        "print(type(y_eval[0]))\n",
        "print(X_eval)\n",
        "print(y_eval)\n",
        "\n",
        "print(X_eval[0])\n",
        "print(y_eval[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDEJD_zRzzFv"
      },
      "source": [
        "class HumorDataset(Dataset):\n",
        "  def __init__(self, text_data, input_labels, tokenizer):\n",
        "        super().__init__()\n",
        "        \n",
        "        data = []\n",
        "        labels = []\n",
        "        ## to be changed if needed\n",
        "        ## to be changed if needed\n",
        "        # max_length = 217 # for bert_base_cased\n",
        "        max_length = 207\n",
        "        self.max_length = max_length\n",
        "\n",
        "        for i, sample in enumerate(text_data):\n",
        "          tokens = tokenizer.tokenize(sample)\n",
        "          data_idxs = tokenizer.encode(sample)\n",
        "          \n",
        "          padded = np.zeros(max_length)\n",
        "          # if max_length < 217: # for bert_base_cased\n",
        "          if max_length < 207:\n",
        "            padded = data_idxs[:max_length]\n",
        "          else:\n",
        "            padded[:len(data_idxs)] = data_idxs\n",
        "          \n",
        "          data.append(padded)\n",
        "          \n",
        "          labels.append(input_labels[i])\n",
        "          \n",
        "        self.data = torch.tensor(data, dtype=torch.long)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        return self.data[index], self.labels[index]\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os6fOPq24d4q"
      },
      "source": [
        "## to be changed\n",
        "pretrained = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained)\n",
        "tokenizer.do_basic_tokenize = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX-TpwBUCAe8"
      },
      "source": [
        "#set batch size\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Nalcwg3aRK"
      },
      "source": [
        "train_dataset = HumorDataset(X_train, y_train, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzEVIdz7XJnd"
      },
      "source": [
        "train_loader = DataLoader(train_dataset,\n",
        "        shuffle=True,\n",
        "        batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-KUwwAwGDV-"
      },
      "source": [
        "# Configure model parameters\n",
        "config = BertConfig.from_pretrained(pretrained)\n",
        "config.num_labels = 2\n",
        "config.num_hidden_layers = 1\n",
        "config.num_attention_heads = 1\n",
        "config.output_attentions = True\n",
        "\n",
        "## to be changed\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    pretrained,\n",
        "    num_labels=2,\n",
        "    num_hidden_layers=1,\n",
        "    num_attention_heads=1,\n",
        "    output_attentions=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HogNvdVl_38N"
      },
      "source": [
        "#architecture\n",
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIvWtst0_4nw"
      },
      "source": [
        "#define optimizer and loss\n",
        "# optimizer = optim.Adam(model.parameters())\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "# optimizer = optim.RMSprop(model.parameters())\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    for k in range (0, len(y)):\n",
        "      output = torch.argmax(preds[k])\n",
        "      if output==y[k]:\n",
        "        correct += 1\n",
        "    acc = correct/len(y)\n",
        "    return acc\n",
        "    \n",
        "#push to cuda if available\n",
        "# model = model.to(device)\n",
        "# criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HALlZObFAGJT"
      },
      "source": [
        "def train(model, iterator, optimizer):\n",
        "    \n",
        "    #initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    #set the model in training phase\n",
        "    model.train()\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "        data, labels = batch\n",
        "\n",
        "        #resets the gradients after every batch\n",
        "        optimizer.zero_grad() \n",
        "        data = data.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(data, labels=labels)\n",
        "        \n",
        "        #compute the loss\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        acc = binary_accuracy(outputs.logits, labels)   \n",
        "        \n",
        "        #backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        #update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        #loss and accuracy\n",
        "        epoch_loss += loss\n",
        "        epoch_acc += acc\n",
        "        \n",
        "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0hq-PEcA5g3"
      },
      "source": [
        "def evaluate(model, iterator):\n",
        "    \n",
        "    #initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "            data, labels = batch\n",
        "            data = data.to(device)\n",
        "            labels = labels.to(device)\n",
        "        \n",
        "            outputs = model(data, labels=labels)\n",
        "            \n",
        "            #compute loss and accuracy\n",
        "            loss = outputs[0]\n",
        "            acc = binary_accuracy(outputs.logits, labels)\n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss\n",
        "            epoch_acc += acc\n",
        "        \n",
        "\n",
        "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp9_75RK-FHV"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "## pushing to cuda\n",
        "model = model.to(device)  \n",
        "\n",
        "eval_dataset = HumorDataset(X_eval, y_eval, tokenizer)\n",
        "eval_loader = DataLoader(eval_dataset,\n",
        "      shuffle=True,\n",
        "      batch_size=BATCH_SIZE)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "        \n",
        "    # store starting time (training)\n",
        "    begin = time.time()\n",
        "\n",
        "    #train the model\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer)\n",
        "\n",
        "    # store end time (training)\n",
        "    end = time.time()\n",
        "\n",
        "    # print train time\n",
        "    print(f\"Train time is {end - begin}\")\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, eval_loader)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights_bertwithbert_test.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHTfJ1zzhMWk"
      },
      "source": [
        "#load weights\n",
        "path='saved_weights_bertwithbert_test.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "\n",
        "test_dataset = HumorDataset(X_test, y_test, tokenizer)\n",
        "test_loader = DataLoader(test_dataset,\n",
        "      shuffle=True,\n",
        "      batch_size=BATCH_SIZE)\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb6ljsmCCgoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4820f54-3572-49f8-d982-5d98b71dfae6"
      },
      "source": [
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTest Loss: 0.132 | Test Acc: 94.87%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jrf9aFjctSk"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def confusion_mat(model, iterator):\n",
        "    \n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "      #initializing confusion matrix\n",
        "      cm = [[0,0],[0,0]]\n",
        "\n",
        "      for i, batch in enumerate(iterator):\n",
        "          data, labels = batch\n",
        "          data = data.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          #get outputs\n",
        "          outputs = model(data, labels=labels)\n",
        "\n",
        "          #change outputs into predictions\n",
        "          y_pred = outputs.logits.cpu()\n",
        "          pred = torch.argmax(y_pred, 1)\n",
        "\n",
        "          #true labels\n",
        "          y_true = labels.cpu()\n",
        " \n",
        "          #add this batch to confusion matrix\n",
        "          cm += confusion_matrix(y_true, pred)\n",
        "\n",
        "    return cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaYG4GfJdr-I",
        "outputId": "3a232721-9020-4241-b0cf-d73d630b9a91"
      },
      "source": [
        "cf_matrix = confusion_mat(model, test_loader)\n",
        "print(cf_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2254   50]\n",
            " [ 120  931]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "c_T5hD-FguvR",
        "outputId": "2329bfe9-24f3-4fee-d490-4e5862eef8ed"
      },
      "source": [
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = [\"Not humour\", \"Humour\"]\n",
        "\n",
        "df_cm = pd.DataFrame(cf_matrix, index = [i for i in classes],\n",
        "                     columns = [i for i in classes])\n",
        "plt.figure(figsize = (12,7))\n",
        "\n",
        "sn.heatmap(df_cm, annot=True, cmap=\"YlGnBu\", fmt='g')\n",
        "plt.xlabel(\"Predicted\", fontsize = 14)\n",
        "plt.ylabel(\"True\", fontsize = 14)\n",
        "plt.savefig('output.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEFtf7Ko21eA"
      },
      "source": [
        "def misclassifications(model, iterator):\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "      #initialize lists for misclassification examples\n",
        "      examples_nh = [] #misclassified as not humour\n",
        "      examples_h = [] #misclassified as humour\n",
        "\n",
        "      for i, batch in enumerate(iterator):\n",
        "          data, labels = batch\n",
        "          data = data.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          #get outputs and change into predictions\n",
        "          outputs = model(data, labels=labels)\n",
        "          y_pred = outputs.logits.cpu()\n",
        "          pred = torch.argmax(y_pred, 1)\n",
        "          \n",
        "          #true labels\n",
        "          y_true = labels.cpu()\n",
        "\n",
        "          #get misclassifications per batch\n",
        "          for item in range(len(pred)):\n",
        "            if pred[item] != y_true[item]:\n",
        "              if pred[item] == 1:\n",
        "                # print(\"Misclassified as funny:\", item)\n",
        "                # print(X_test[item])\n",
        "                examples_h.append(tokenizer.decode(data[item], \n",
        "                                                   skip_special_tokens = True))\n",
        "              if pred[item] == 0:\n",
        "                # print(\"Misclassified as not funny:\", item)\n",
        "                # print(X_test[item])\n",
        "                examples_nh.append(tokenizer.decode(data[item], \n",
        "                                                    skip_special_tokens = True))\n",
        "            else:\n",
        "              continue\n",
        "\n",
        "    return examples_nh, examples_h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Jqc1RQ3Ndr"
      },
      "source": [
        "misclass_nh, misclass_h = misclassifications(model, test_loader)\n",
        "\n",
        "print(\"MISCLASSIFIED AS NOT FUNNY:\")\n",
        "print(\"Number of sentences: \",len(misclass_nh))\n",
        "for sentence in misclass_nh:\n",
        "  print(sentence)\n",
        "\n",
        "print(\" \")\n",
        "print(\"MISCLASSIFIED AS FUNNY:\")\n",
        "print(\"Number of sentences: \",len(misclass_h))\n",
        "for sentence in misclass_h:\n",
        "  print(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
